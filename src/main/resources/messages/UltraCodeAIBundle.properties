# UltraCodeAI Plugin Messages and Localization

# General Plugin Information
plugin.name=UltraCodeAI
plugin.description=Local AI-powered coding assistant with Qwen 2.5 Coder
plugin.vendor=UltraCodeAI Team

# Action Names and Descriptions
action.explain.code=Explain Code
action.explain.code.description=Explain selected code using AI
action.toggle.completion=Toggle AI Completion
action.toggle.completion.description=Enable/disable AI code completion
action.open.chat=Open AI Chat
action.open.chat.description=Open AI chat panel
action.fix.code=AI Fix Suggestion
action.fix.code.description=Get AI suggestions to fix code issues
action.generate.tests=Generate Unit Tests
action.generate.tests.description=Generate unit tests using AI
action.optimize.code=Optimize Code
action.optimize.code.description=Get AI suggestions to optimize code performance

# Settings UI
settings.title=UltraCodeAI Settings
settings.features.title=Features
settings.ai.model.title=AI Model Settings
settings.performance.title=Performance Settings
settings.enable.completion=Enable AI Code Completion
settings.enable.error.detection=Enable AI Error Detection
settings.enable.explanation=Enable Code Explanation
settings.ollama.url=Ollama Server URL
settings.model.name=Model Name
settings.max.tokens=Max Tokens
settings.temperature=Temperature
settings.enable.caching=Enable Response Caching
settings.low.power.mode=Low Power Mode
settings.completion.delay=Completion Delay (ms)

# Tooltips
tooltip.completion=Show AI-powered code completion suggestions as you type
tooltip.error.detection=Analyze code for potential errors and issues in real-time
tooltip.explanation=Enable right-click code explanation feature
tooltip.ollama.url=URL of your local Ollama server (default: http://localhost:11434)
tooltip.model.name=AI model to use (default: qwen2.5-coder:7b)
tooltip.max.tokens=Maximum tokens per AI response (50-4096)
tooltip.temperature=AI creativity level (0.0 = deterministic, 2.0 = very creative)
tooltip.caching=Cache AI responses to improve performance and reduce latency
tooltip.low.power=Reduce AI calls to save battery and CPU usage
tooltip.completion.delay=Delay before showing completions (100-5000ms)

# Status Messages
status.ai.ready=AI Ready
status.ai.loading=Model Loading
status.ai.offline=Ollama Offline
status.ai.error=AI Error

# Error Messages
error.ollama.not.running=Ollama server is not running. Please start it with 'ollama serve'
error.model.not.found=Model not found. Please install it with 'ollama pull qwen2.5-coder:7b'
error.connection.failed=Failed to connect to Ollama server
error.request.timeout=Request timed out. The model might be loading
error.invalid.response=Invalid response from AI model
error.settings.validation=Settings validation failed

# Success Messages
success.settings.saved=Settings saved successfully
success.model.available=AI model is available and ready
success.connection.established=Connected to Ollama server
success.cache.cleared=Cache cleared successfully

# Dialog Titles
dialog.setup.help=UltraCodeAI Setup Help
dialog.ai.explanation=AI Code Explanation
dialog.error=UltraCodeAI Error
dialog.settings=UltraCodeAI Settings
dialog.about=About UltraCodeAI

# Notification Messages
notification.setup.required=UltraCodeAI Setup Required
notification.model.loaded=AI model loaded successfully
notification.feature.enabled=Feature enabled
notification.feature.disabled=Feature disabled

# Chat Messages
chat.welcome=Welcome to UltraCodeAI! How can I help you with your code?
chat.thinking=Thinking...
chat.error.occurred=An error occurred while processing your request
chat.no.selection=No code selected. Please select some code first.
chat.cleared=Conversation cleared

# Quick Actions
quick.action.debug=Debug Code
quick.action.explain=Explain Code  
quick.action.optimize=Optimize Code
quick.action.test=Generate Tests

# Code Analysis
analysis.complexity.low=Low Complexity
analysis.complexity.medium=Medium Complexity
analysis.complexity.high=High Complexity
analysis.complexity.very.high=Very High Complexity

# Setup Instructions
setup.install.ollama=Install Ollama: curl -fsSL https://ollama.ai/install.sh | sh
setup.pull.model=Pull model: ollama pull qwen2.5-coder:7b
setup.start.server=Start server: ollama serve
setup.verify=Verify setup: curl http://localhost:11434

# Completion Messages
completion.ai.suggestion=AI Suggestion
completion.confidence=Confidence
completion.generating=Generating AI completion...
completion.failed=Failed to generate completion
completion.cached=Cached suggestion

# Context Menu
context.menu.ai.actions=UltraCodeAI Actions
context.menu.explain.selection=Explain Selection
context.menu.fix.issues=Fix Issues
context.menu.generate.docs=Generate Documentation
